{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "lang='en'\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restaurant review class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestaurantReviewFeatures(object):\n",
    "    \"\"\"Stores reviews data and rating data for one restaurant\n",
    "    \n",
    "    Attributes:\n",
    "        id (str): id of the restaurant, this will be used as Primary Key\n",
    "        index (int): index of last added review\n",
    "        rating (dict): rating of this restaurant\n",
    "        reviews (dict): reviews of this restaurant\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        \"\"\"Initialize class\n",
    "        \"\"\"\n",
    "        self.id = key    \n",
    "        self.index = 0\n",
    "        self.rating = {}\n",
    "        self.reviews = {}\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"returns features of a specific review\n",
    "        \n",
    "        Args:\n",
    "            idx (int): index of the review\n",
    "        \n",
    "        Returns:\n",
    "            dict: The review dictionary at index=idx.\n",
    "            \n",
    "        \"\"\"\n",
    "        return self.reviews[idx]\n",
    "\n",
    "    def __len_(self):\n",
    "        \"\"\"returns total reviews for this restaurant\n",
    "        \n",
    "        Returns:\n",
    "            int: total reviews for this restaurant\n",
    "        \"\"\"\n",
    "        return self.index\n",
    "    \n",
    "    def addReview(self, rating,unigrams=[], bigrams1=[], bigrams2=[], trigrams=[], dataset=\"\", nouns=[], raw=[]):\n",
    "        \"\"\"Adds a review\n",
    "        \n",
    "        Args:\n",
    "            rating (float): rating of the review\n",
    "            'nouns' (list): list of noun_chunks in review\n",
    "            raw (list): list of tokens in review (raw features)\n",
    "            unigrams (list): list of unigrams in review\n",
    "            bigrams1 (list): list of bigrams 'ADJ + next word'\n",
    "            \"bigrams2\" (list): list of bigrams 'prev word + ADJ'\n",
    "            \"trigrams\" (list): list of trigrams\n",
    "            \"rating\" (list): rating of that review\n",
    "            \"dataset\" (str): original dataset\n",
    "        \"\"\"\n",
    "        if len(unigrams)>0 or len(bigrams1)>0 or len(trigrams) or len(raw)>0:\n",
    "            self.reviews[self.index] = {'nouns':nouns, 'raw':raw, 'unigrams':unigrams, 'bigrams':bigrams1, 'bigrams2':bigrams2, 'trigrams':trigrams, 'rating':rating,'dataset':dataset}\n",
    "            self.index += 1\n",
    "    \n",
    "    def addRating(self, rating, dataset):\n",
    "        \"\"\"Adds rating for the restaurant\n",
    "        \n",
    "        Args:\n",
    "            rating (float): rating value\n",
    "            dataset (string): original dataset\n",
    "        \"\"\"\n",
    "        if rating > 0:\n",
    "            self.rating[dataset] = rating\n",
    "    \n",
    "    def getRating(self, dataset=\"avg\"):\n",
    "        \"\"\"returns rating for the restaurant\n",
    "        \n",
    "        Args:\n",
    "            dataset (string): original dataset name.\n",
    "            possible values for dataset = [\"avg\",\"google\",\"yelp\"]\n",
    "            \n",
    "        Returns:\n",
    "            float: rating value\n",
    "        \"\"\"\n",
    "        if dataset == \"avg\":\n",
    "            return float(sum(self.rating.values()))/len(self.rating)\n",
    "        else:\n",
    "            return self.rating[dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## review cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(doc):\n",
    "    \"\"\"Initial cleanup of the review\n",
    "    \n",
    "    Args:\n",
    "        doc (str): review string\n",
    "        \n",
    "    Note:\n",
    "        removes all stopwords and punctuations from the string\n",
    "    \n",
    "    Returns:\n",
    "        str: cleaned string\n",
    "    \"\"\"\n",
    "    doc = nlp(doc, disable=['parser', 'ner'])\n",
    "    tokens = [tok.lemma_.lower().strip() for tok in doc if (tok.lemma_ != '-PRON-' and tok.is_stop==False and tok.is_punct==False)]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process one restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOneRestaurant(restaurant, log=True):\n",
    "    \"\"\"Process reviews of one restaurnat\n",
    "    \n",
    "    Note:\n",
    "        returns RestaurantReviewFeatures object containing all reivews and rating information\n",
    "        \n",
    "    Args:\n",
    "        restaurant (dict): dictionary containing restaurant info\n",
    "    \n",
    "    Returns:\n",
    "        Object: RestaurantReviewFeatures class object\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if \"google\" in restaurant:\n",
    "        restaurant_id = restaurant[\"google\"][\"place_id\"]\n",
    "    else:\n",
    "        restaurant_id = restaurant[\"yelp\"][\"id\"]\n",
    "    \n",
    "    r = RestaurantReviewFeatures(restaurant_id)\n",
    "    for dataset in restaurant:\n",
    "        #print(\"DataSet:\" + dataset)    \n",
    "        if \"rating\" in restaurant[dataset]:\n",
    "            r.addRating(restaurant[dataset][\"rating\"], dataset.replace(\"ui\",\"\"))\n",
    "        \n",
    "        if \"reviews\" not in restaurant[dataset].keys():\n",
    "            if log:\n",
    "                print(\"{} : NO reviews found for {} dataset\".format(restaurant_id,dataset))\n",
    "        else:\n",
    "            ##print(len(restaurant[dataset][\"reviews\"]))\n",
    "            for review in restaurant[dataset][\"reviews\"]:\n",
    "                review_text = review[\"text\"].strip()\n",
    "                review_text = cleanup_text(review_text)\n",
    "                #print(review_text)\n",
    "                doc = nlp(review_text, disable=['ner'])\n",
    "                uni_feature_list = []\n",
    "                bi_feature_list = []\n",
    "                bi_feature_list2 = []\n",
    "                tri_feature_list = []\n",
    "                raw_feature_list = review_text.split(' ')\n",
    "                for i in range(len(doc)):\n",
    "                    token = doc[i]\n",
    "                    if token.tag_.startswith('J'):\n",
    "                        uni_feature_list.append(token.lemma_)\n",
    "                        if i<len(doc)-1:\n",
    "                            #print(token.text,\":\" ,doc[i-1].lemma_, token.lemma_, doc[i+1].lemma_)\n",
    "                            bi_feature_list.append(token.lemma_+\" \"+doc[i+1].lemma_)\n",
    "                            if i>0:\n",
    "                                tri_feature_list.append(doc[i-1].lemma_+\" \"+token.lemma_+\" \"+doc[i+1].lemma_)\n",
    "                        if i>0:\n",
    "                            bi_feature_list2.append(doc[i-1].lemma_+\" \"+token.lemma_)\n",
    "                            \n",
    "                            \n",
    "                review_stars = None\n",
    "                if \"stars\" in review:\n",
    "                    review_stars = review[\"stars\"]\n",
    "                if \"rating\" in review:\n",
    "                    review_stars = review[\"rating\"]\n",
    "                \n",
    "                if review_stars != None:\n",
    "                    r.addReview(review_stars, unigrams=uni_feature_list, bigrams1=bi_feature_list,\n",
    "                                bigrams2= bi_feature_list2, trigrams=tri_feature_list, raw=raw_feature_list,\n",
    "                                nouns=doc.noun_chunks, dataset=dataset)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code to process one restaurant from combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChIJhc9r0waWwoAR70Xf1HZKbo4 : NO reviews found for yelp dataset\n",
      "ChIJUVPwAv-9woAR_dnF22r-D00 : NO reviews found for yelp dataset\n",
      "ChIJQapGk_y9woARKIZHrNZEiwE : NO reviews found for yelp dataset\n",
      "ChIJF4wAsh-WwoAR1Kniw_Fp5tw : NO reviews found for yelp dataset\n",
      "ChIJzc2KDv29woARBsKstcFPywQ : NO reviews found for yelp dataset\n",
      "ChIJv52y0QaWwoARf-i27AO-mwk : NO reviews found for yelp dataset\n",
      "ChIJa8kfNxiWwoARD2sK_jeDmXU : NO reviews found for yelp dataset\n",
      "ChIJGc8NNvS9woAR9CH2BEPBtRQ : NO reviews found for yelp dataset\n",
      "ChIJz7DIi_C9woARgtCR9Dh1sRU : NO reviews found for yelp dataset\n",
      "ChIJ3XGSYe6_woARNaMGJY-URaQ : NO reviews found for yelp dataset\n",
      "ChIJa53kr8K_woARFIQv7Qx7hvQ : NO reviews found for yelp dataset\n",
      "ChIJx2CNWOW_woARkaMnjvUpI5g : NO reviews found for yelp dataset\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-af3b3c5a8464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mrestaurant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessOneRestaurant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestaurant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m#assert(r.id not in review_dict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#review_dict[r.id] = r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-248653888666>\u001b[0m in \u001b[0;36mprocessOneRestaurant\u001b[1;34m(restaurant, log)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mreview_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanup_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;31m#print(review_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0muni_feature_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mbi_feature_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utkar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__call__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.precompute_hiddens.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utkar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\spacy\\_ml.py\u001b[0m in \u001b[0;36mbegin_update\u001b[1;34m(self, X, drop)\u001b[0m\n\u001b[0;32m    149\u001b[0m             self.W.reshape((self.nF*self.nO*self.nP, self.nI)).T)\n\u001b[0;32m    150\u001b[0m         \u001b[0mYf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mYf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdY_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utkar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\spacy\\_ml.py\u001b[0m in \u001b[0;36m_add_padding\u001b[1;34m(self, Yf)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mYf_padded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mYf_padded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utkar\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "review_dict = {}\n",
    "noun_chunks = set()\n",
    "with open(\"C:\\\\Users\\\\utkar\\\\Downloads\\\\large_data.json\",\"r\") as f:\n",
    "    ## use parallel processing (Pool.map()) here to expedite processing\n",
    "    while(True):\n",
    "        line = f.readline()\n",
    "\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        restaurant = json.loads(line)\n",
    "        r = processOneRestaurant(restaurant)\n",
    "        #assert(r.id not in review_dict)\n",
    "        #review_dict[r.id] = r\n",
    "        for k in r.reviews.keys():\n",
    "            nouns = r.reviews[k][\"nouns\"]\n",
    "            for n in list(nouns):\n",
    "                noun_chunks.add(n.text)\n",
    "        del r\n",
    "        \n",
    "print(\"Number of restaurants: \" + len(review_dict))\n",
    "#f.close()\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"{}s to process {} restaurants\".format(t2-t1, len(review_dict)))\n",
    "\n",
    "f =open(\"C:\\\\Users\\\\utkar\\\\Downloads\\\\nouns.txt\",\"w\")\n",
    "data = str(list(noun_chunks)).replace(\",\",\"\\n\").replace(\"'\")\n",
    "f.write()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict['ChIJQapGk_y9woARKIZHrNZEiwE'].rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambience = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
