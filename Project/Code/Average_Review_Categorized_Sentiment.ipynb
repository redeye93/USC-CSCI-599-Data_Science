{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "DATA_PATH = \"C:/Users/utkar/Downloads/large_data.json\" # Change this for data\n",
    "\n",
    "#find sentiment vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# The synonyms of the 3 categories\n",
    "temp_dict = defaultdict(list)\n",
    "for key in [\"ambiance\",\"food\",\"service\"]:\n",
    "        for syn in wn.synsets(key):\n",
    "                temp_dict[key].append(syn.name())\n",
    "m = {'food':0,'service':1,'ambiance':2, 'other':3}\n",
    "m_back = {0: 'food', 1: 'service', 2: 'ambiance', 3: 'other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorized_sentence(sentence):\n",
    "    noun_labels = []\n",
    "    noun_chunk_int_label = {}\n",
    "    noun_chunk_final_label = {}\n",
    "    \n",
    "    # Clean the text\n",
    "    sentence = sentence.strip()\n",
    "    sentence = nlp(sentence, disable=['parser', 'ner'])\n",
    "    sentence = [tok.lemma_.lower().strip() for tok in sentence if (tok.lemma_ != '-PRON-' and tok.is_stop==False and tok.is_punct==False)]\n",
    "    sentence = ' '.join(sentence)\n",
    "    \n",
    "    # Remove all the numbers\n",
    "    formatted_chunk = ''.join(e for e in sentence if (e.isalpha() or e==' '))\n",
    "    \n",
    "    for word in formatted_chunk.split(' '):\n",
    "        word_hypernym_set = set()\n",
    "        for syn in wn.synsets(word, pos=wn.NOUN):\n",
    "            #print(wn.synset(syn.name()).hypernym_paths())\n",
    "            for hypernym in wn.synset(syn.name()).hypernym_paths()[0]:\n",
    "                word_hypernym_set.add(hypernym.name())\n",
    "\n",
    "            #print(word_hypernym_set)\n",
    "            word_label = set()\n",
    "            for key in temp_dict:\n",
    "                for syn in temp_dict[key]:\n",
    "                    if syn in word_hypernym_set:\n",
    "                        word_label.add(key)\n",
    "                        noun_chunk_int_label[key] = 1\n",
    "                        noun_chunk_final_label[m[key]] = 1\n",
    "                noun_labels.append(word_label)\n",
    "    if len(noun_chunk_final_label.keys())>0:\n",
    "        return set(noun_chunk_final_label.keys())\n",
    "    else:\n",
    "        return set([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "all_restaurants_reviews = []\n",
    "inputfile = open(DATA_PATH, \"r\")\n",
    "index = 0\n",
    "#Read all the restaurant data\n",
    "for line in inputfile:\n",
    "    index += 1\n",
    "    # Fetch the yelp ui\n",
    "    restaurant = json.loads(line)\n",
    "\n",
    "    if \"google\" in restaurant:\n",
    "        restaurant_id = restaurant[\"google\"][\"place_id\"]\n",
    "    else:\n",
    "        restaurant_id = restaurant[\"yelp\"][\"id\"]\n",
    "    \n",
    "    # Initialize th erestaurant object\n",
    "    r_dict = {\n",
    "        'id': restaurant_id,\n",
    "        'food_neg': 0,\n",
    "        'food_neu': 0,\n",
    "        'food_pos': 0,\n",
    "        'food_compound': 0,\n",
    "        'service_neg': 0,\n",
    "        'service_neu': 0,\n",
    "        'service_pos': 0,\n",
    "        'service_compound': 0,\n",
    "        'ambiance_neg': 0,\n",
    "        'ambiance_neu': 0,\n",
    "        'ambiance_pos': 0,\n",
    "        'ambiance_compound': 0,\n",
    "        'other_neg': 0,\n",
    "        'other_neu': 0,\n",
    "        'other_pos': 0,\n",
    "        'other_compound': 0\n",
    "    }\n",
    "\n",
    "    count = {\n",
    "        \"food\": 0,\n",
    "        \"service\": 0,\n",
    "        \"ambiance\": 0,\n",
    "        \"other\": 0\n",
    "    }\n",
    "\n",
    "    # Focus on the yelp reviews\n",
    "    restaurant_yelpui = restaurant['uiyelp']\n",
    "    for review in restaurant_yelpui['reviews']:\n",
    "        for sentence in nltk.sent_tokenize(review['text']):\n",
    "            category = categorized_sentence(sentence)\n",
    "            snt = analyser.polarity_scores(sentence)\n",
    "\n",
    "            for c in category:\n",
    "                count[m_back[c]] += 1\n",
    "                for s in snt:\n",
    "                    r_dict[m_back[c] + \"_\" + s] += snt[s]\n",
    "\n",
    "    for c in m.keys():\n",
    "        r_dict[c + \"_neg\"] /= (1, count[c])[count[c]>0]\n",
    "        r_dict[c + \"_neu\"] /= (1, count[c])[count[c]>0]\n",
    "        r_dict[c + \"_pos\"] /= (1, count[c])[count[c]>0]\n",
    "        r_dict[c + \"_compound\"] /= (1, count[c])[count[c]>0]\n",
    "\n",
    "    all_restaurants_reviews.append(r_dict)\n",
    "    \n",
    "    print(\"Restaurant \" + str(index) + \" processed.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_restaurants_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('C:/Users/utkar/Downloads/output.csv', 'w') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.DictWriter(f, all_restaurants_reviews[0].keys())\n",
    "    w.writeheader()\n",
    "    for restaurant in all_restaurants_reviews:\n",
    "        w.writerow(restaurant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
